bootstrap.2013 <- filter(bootstrap_resample, yr==2013)
bootstrap.2013.2 <- cbind.data.frame(genome = LETTERS[1:19], counts = apply(array(LETTERS[1:length(levels(data_set$genome))]), 1, FUN=function(x){
sum(data_set$genome==x)
}))
bootstrap.2013.3 <- mutate(bootstrap.2013.2, p=counts/sum(counts))
#Save results
p.2013 <- bootstrap.2013.3$p
results.2013 <- cbind.data.frame(results.2013, p.2013)
create_bootstrap_data <- function(data_set){} cbind.data.frame(genome = LETTERS[1:19], counts = apply(array(LETTERS[1:length(levels(data_set$genome))]), 1, FUN=function(x){
sum(data_set$genome==x)}
}))
create_bootstrap_data <- function(data_set){} cbind.data.frame(genome = LETTERS[1:19], counts = apply(array(LETTERS[1:length(levels(data_set$genome))]), 1, FUN=function(x){
sum(data_set$genome==x)
}))}
create_bootstrap_data <- function(data_set){} cbind.data.frame(genome = LETTERS[1:19], counts = apply(array(LETTERS[1:length(levels(data_set$genome))]), 1, FUN=function(x){
sum(data_set$genome==x)
}))}
create_bootstrap_data <- function(data_set){cbind.data.frame(genome = LETTERS[1:19], counts = apply(array(LETTERS[1:length(levels(data_set$genome))]), 1, FUN=function(x){
sum(data_set$genome==x)
}))}
bootstrap.2013.2 <- create_bootstrap_data(bootstrap.2013)
bootstrap.2013.2
# Make a table for 2013 data and calculate that year's p.i values
bootstrap.2013 <- filter(bootstrap_resample, yr==2013)
bootstrap.2013 <- create_bootstrap_data(bootstrap.2013)
bootstrap.2013 <- mutate(bootstrap.2013.2, p=counts/sum(counts))
bootstrap.2013
#Save results
p.2013 <- bootstrap.2013$p
results.2013 <- cbind.data.frame(results.2013, p.2013)
#Repeat above for 2016
bootstrap.2016 <- filter(bootstrap_resample, yr==2016)
bootstrap.2016 <- create_bootstrap_data(bootstrap.2016)
bootstrap.2016 <- mutate(bootstrap.2016, p=counts/sum(counts))
#Save results
p.2016 <- bootstrap.2016$p
results.2016 <- cbind.data.frame(results.2016, p.2016)
results.2013
n <- 5
results.2013 <- LETTERS[1:19]
results.2016 <- LETTERS[1:19]
for (i in 1:n){
# Pick the 525 individuals for the resample.
bootstrap_resample <- sample_n(d.ll,525, replace = TRUE)
colnames(bootstrap_resample) <- c("genome","yr")
# Make a table for 2013 data and calculate that year's p.i values
bootstrap.2013 <- filter(bootstrap_resample, yr==2013)
bootstrap.2013 <- create_bootstrap_data(bootstrap.2013)
bootstrap.2013 <- mutate(bootstrap.2013, p=counts/sum(counts))
p.2013 <- bootstrap.2013$p
results.2013 <- cbind.data.frame(results.2013, p.2013)
#Repeat above for 2016
bootstrap.2016 <- filter(bootstrap_resample, yr==2016)
bootstrap.2016 <- create_bootstrap_data(bootstrap.2016)
bootstrap.2016 <- mutate(bootstrap.2016, p=counts/sum(counts))
p.2016 <- bootstrap.2016$p
results.2016 <- cbind.data.frame(results.2016, p.2016)
}
results.2013
results.2016
results.2013
dl$genome
d.l$genome
d.l
colnames(d.l) <- c("genome", "yr", "counts", "id")
d.ll <- untable(d.l, d.l$counts)[, -c(3,4)]
###1b
##### 2013:
d.l.2013 <- filter(d.l, yr==2013)  #choose only 2013
d.l.2013
source("source.R")
### Reading data in
d <- read.csv("count_genome.csv", header=TRUE)
d.l <- reshape(d, varying = paste("X", 2009:2016, sep=""), v.names = "counts", timevar = "yr", time = 2009:2016, direction = "long")
colnames(d.l) <- c("genome", "yr", "counts", "id")
d.ll <- untable(d.l, d.l$counts)[, -c(3,4)]
###1b
##### 2013:
d.l.2013 <- filter(d.l, yr==2013)  #choose only 2013
d.l.2013 <- arrange(d.l.2013, genome) %>% #make sure genomes are in order
mutate(i = c(1:nrow(d.l.2013))) %>% #label data with the numbers "i"
mutate(p.hat.i=counts/(sum(d.l.2013$counts)), #make a column of the MLE p.hat.i = xi/n
var.p.hat.i=(p.hat.i)*(1-p.hat.i)/(sum(d.l.2013$counts)),
CI.90.upper = qnorm(0.95, mean=(p.hat.i), sd=(sqrt(var.p.hat.i))), #Make columns with 90% confidence interval bounds
CI.90.lower = qnorm(0.05, mean=(p.hat.i), sd=(sqrt(var.p.hat.i))))
### plot MLE and confidence interval:
ggplot(d.l.2013, aes(i,p.hat.i)) +
geom_pointrange(aes(ymin=CI.90.lower, ymax=CI.90.upper)) +
ggtitle("2013")
### 2016:
d.l.2016 <- filter(d.l, yr==2016)  #choose only 2016
d.l.2016 <- arrange(d.l.2016, genome) %>% #make sure genomes are in order
mutate(i = c(1:nrow(d.l.2016))) %>%
mutate(p.hat.i=counts/(sum(d.l.2016$counts)), #make a column of the MLE p.hat.i = xi/n
var.p.hat.i=(p.hat.i)*(1-p.hat.i)/(sum(d.l.2016$counts)),
CI.90.upper = qnorm(0.95, mean=(p.hat.i), sd=(sqrt(var.p.hat.i))), #Make columns with 90% confidence interval bounds
CI.90.lower = qnorm(0.05, mean=(p.hat.i), sd=(sqrt(var.p.hat.i))))
### plot MLE and confidence interval:
ggplot(d.l.2016, aes(i,p.hat.i)) +
geom_pointrange(aes(ymin=CI.90.lower, ymax=CI.90.upper)) +
ggtitle("2016")
### Wald test statistic (T) for each year = sqrt((p_hat_i - p)^2/(var(p_hat_i)))
### Here, comparing genomes A and B (1 and 2, respectively)
(T.2013 <- sqrt(((d.l.2013$p.hat.i[1] - d.l.2013$p.hat.i[2])^2) / (d.l.2013$var.p.hat.i[1])))
(T.2016 <- sqrt(((d.l.2016$p.hat.i[1] - d.l.2016$p.hat.i[2])^2) / (d.l.2016$var.p.hat.i[1])))
# T ~ chi-square with 1 df, so find P(T<=t):
# (P.2013 <- pnorm(T.2013, 0, 1))
# (P.2016 <- pnorm(T.2016, 0, 1))
(P.2013 <- pchisq(T.2013, 1))
(P.2016 <- pchisq(T.2016, 1))
# Were A and B significantly different in either year? With two-tailed test, a=.05
(significant.2013 <- (P.2013 >= .975 | P.2013 < .025))
(significant.2016 <- (P.2016 >= .975 | P.2016 < .025))
n <- 5
d.l
results.2013 <- LETTERS[1:19]
results.2013 <- LETTERS[1:length(levels(d.l$genome))]
results.2013 <- LETTERS[1:length(levels(d.l$genome))]
results.2016 <- LETTERS[1:length(levels(d.l$genome))]
quantile(results.2013$a, .95)
results.2013
for (i in 1:n){
# Pick the 525 individuals for the resample.
bootstrap_resample <- sample_n(d.ll,525, replace = TRUE)
colnames(bootstrap_resample) <- c("genome","yr")
# Make a table for 2013 data and calculate that year's p.i values
bootstrap.2013 <- filter(bootstrap_resample, yr==2013)
bootstrap.2013 <- create_bootstrap_data(bootstrap.2013)
bootstrap.2013 <- mutate(bootstrap.2013, p=counts/sum(counts))
p.2013 <- bootstrap.2013$p
results.2013 <- cbind.data.frame(results.2013, p.2013)
#Repeat above for 2016
bootstrap.2016 <- filter(bootstrap_resample, yr==2016)
bootstrap.2016 <- create_bootstrap_data(bootstrap.2016)
bootstrap.2016 <- mutate(bootstrap.2016, p=counts/sum(counts))
p.2016 <- bootstrap.2016$p
results.2016 <- cbind.data.frame(results.2016, p.2016)
}
# Reorganize the results tables
names(results.2013) <- c("genome",1:n)
results.2013
rownames(results.2013) <- results.2013$genome
results.2013 <- results.2013[,-1]
results.2013 <- t(results.2013)
results.2013 <- as.data.table(results.2013)
results.2013
names(results.2016) <- c("genome",1:n)
rownames(results.2016) <- results.2016$genome
results.2016 <- results.2016[,-1]
results.2016 <- t(results.2016)
results.2016 <- as.data.table(results.2016)
quantile(results.2013$a, .95)
quantile(results.2013$A, .95)
x="A"
results.2013
results.2013$A
results.2013$x
results.2013==x
colnames(results.2013)
colnames(results.2013)==x
results.2013[colnames(results.2013)==x]
results.2013[colnames(results.2013)==x,]
results.2013[,colnames(results.2013)==x]
apply(results.2013,2,FUN=function(x){
quantile(x, .95)
quantile(x, .05)
quantile(x, .50)
})
CI.90.2013 <- cbind.data.frame(c(1:19),
c(quantile(results.2013$a, .95),quantile(results.2013$b, .95),
quantile(results.2013$c, .95),quantile(results.2013$d, .95),
quantile(results.2013$e, .95),quantile(results.2013$f, .95),
quantile(results.2013$g, .95),quantile(results.2013$h, .95),
quantile(results.2013$i, .95),quantile(results.2013$j, .95),
quantile(results.2013$k, .95),quantile(results.2013$l, .95),
quantile(results.2013$m, .95),quantile(results.2013$n, .95),
quantile(results.2013$o, .95),quantile(results.2013$p, .95),
quantile(results.2013$q, .95),quantile(results.2013$r, .95),
quantile(results.2013$s, .95)
),
c(quantile(results.2013$a, .05),quantile(results.2013$b, .05),
quantile(results.2013$c, .05),quantile(results.2013$d, .05),
quantile(results.2013$e, .05),quantile(results.2013$f, .05),
quantile(results.2013$g, .05),quantile(results.2013$h, .05),
quantile(results.2013$i, .05),quantile(results.2013$j, .05),
quantile(results.2013$k, .05),quantile(results.2013$l, .05),
quantile(results.2013$m, .05),quantile(results.2013$n, .05),
quantile(results.2013$o, .05),quantile(results.2013$p, .05),
quantile(results.2013$q, .05),quantile(results.2013$r, .05),
quantile(results.2013$s, .05)
),
c(quantile(results.2013$a, .50),quantile(results.2013$b, .50),
quantile(results.2013$c, .50),quantile(results.2013$d, .50),
quantile(results.2013$e, .50),quantile(results.2013$f, .50),
quantile(results.2013$g, .50),quantile(results.2013$h, .50),
quantile(results.2013$i, .50),quantile(results.2013$j, .50),
quantile(results.2013$k, .50),quantile(results.2013$l, .50),
quantile(results.2013$m, .50),quantile(results.2013$n, .50),
quantile(results.2013$o, .50),quantile(results.2013$p, .50),
quantile(results.2013$q, .50),quantile(results.2013$r, .50),
quantile(results.2013$s, .50)
)
)
CI.90.2013
apply(results.2013,2,FUN=function(x){
quantile(x, .95)
quantile(x, .05)
quantile(x, .50)
})
lapply(results.2013,2,FUN=function(x){
quantile(x, .95)
quantile(x, .05)
quantile(x, .50)
})
lapply(results.2013,FUN=function(x){
quantile(x, .95)
quantile(x, .05)
quantile(x, .50)
})
sapply(results.2013,FUN=function(x){
quantile(x, .95)
quantile(x, .05)
quantile(x, .50)
})
apply(results.2013,2,FUN=function(x){
quantile(x, .95)
quantile(x, .05)
quantile(x, .50)
})
results.2013`
results.2013
results.2013$A
quantile(results.2013$A,.95)
quantile(results.2013$A,.95)
quantile(results.2013$A,.95)
apply(results.2013,2,FUN=function(x){
quantile(x, .95)
quantile(x, .05)
quantile(x, .50)
})
apply(results.2013,2,FUN=function(x){
x
})
sum(x)
apply(results.2013,2,FUN=function(x){
sum(x)
})
apply(results.2013,2,FUN=function(x){
quantile(x, .95)
quantile(x, .05)
quantile(x, .50)
})
apply(results.2013,2,FUN=function(x){
list(quantile(x, .95),
quantile(x, .05),
quantile(x, .50))
})
})
apply(results.2013,2,FUN=function(x){
list(quantile(x, .95),
quantile(x, .05),
quantile(x, .50))
})
apply(results.2013,2,FUN=function(x){
list(quantile(x, .95),
quantile(x, .05),
quantile(x, .50))
})$R
apply(results.2013,2,FUN=function(x){
list(quantile(x, .95),
quantile(x, .05),
quantile(x, .50))
})$R[[1]]
genome_letters <- LETTERS[1:length(levels(d.l$genome))]
genome_letters
cbind.data.frame(genome = genome_letters, P95 = apply(array(genome_letters), 1, FUN=function(x){
quantile(results.2013$x, .95))
}))
cbind.data.frame(genome = genome_letters, P95 = apply(array(genome_letters), 1, FUN=function(x){
quantile(results.2013$x, .95))
}))
cbind.data.frame(genome = genome_letters, P95 = apply(array(genome_letters), 1, FUN=function(x){
quantile(results.2013$x, .95))
})
cbind.data.frame(genome = genome_letters, P95 = apply(genome_letters, 1, FUN=function(x){
quantile(results.2013$x, .95))
})
cbind.data.frame(genome_letters,
apply(results.2013,2,FUN=function(x){quantile(x, .95)}),
apply(results.2013,2,FUN=function(x){quantile(x, .95)}),
apply(results.2013,2,FUN=function(x){quantile(x, .95)})
)
cbind.data.frame(genome_letters,
CI_95 = apply(results.2013,2,FUN=function(x){quantile(x, .95)}),
CI_05 =  apply(results.2013,2,FUN=function(x){quantile(x, .05)}),
CI_50 =  apply(results.2013,2,FUN=function(x){quantile(x, .50)})
)
cbind.data.frame(genome = genome_letters,
CI_95 = apply(results.2013,2,FUN=function(x){quantile(x, .95)}),
CI_05 =  apply(results.2013,2,FUN=function(x){quantile(x, .05)}),
CI_50 =  apply(results.2013,2,FUN=function(x){quantile(x, .50)})
)
CI.90.2013 <- cbind.data.frame(genome = genome_letters,
CI_95 = apply(results.2013,2,FUN=function(x){quantile(x, .95)}),
CI_05 =  apply(results.2013,2,FUN=function(x){quantile(x, .05)}),
CI_50 =  apply(results.2013,2,FUN=function(x){quantile(x, .50)})
)
CI.90.2013 <- cbind.data.frame(genome = genome_letters,
lower.bound = apply(results.2013,2,FUN=function(x){quantile(x, .95)}),
upper.bound =  apply(results.2013,2,FUN=function(x){quantile(x, .05)}),
median =  apply(results.2013,2,FUN=function(x){quantile(x, .50)})
)
CI.90.2016 <- cbind.data.frame(genome = genome_letters,
lower.bound = apply(results.2016,2,FUN=function(x){quantile(x, .95)}),
upper.bound =  apply(results.2016,2,FUN=function(x){quantile(x, .05)}),
median =  apply(results.2016,2,FUN=function(x){quantile(x, .50)})
)
# graph the confidence intervals to check for asymmetry
# 2013
ggplot(CI.90.2013, aes(i, median)) +
geom_pointrange(aes(ymin=lower.bound, ymax=upper.bound)) +
ggtitle("2013")
# 2016
ggplot(CI.90.2016, aes(i, median)) +
geom_pointrange(aes(ymin=lower.bound, ymax=upper.bound)) +
ggtitle("2016")
# First sort genotypes by abundance.
sorted.2013 <- d.l.2013 %>%
rename(c(genome = "genome")) %>%
select(genome, counts) %>%
arrange(desc(counts))
sorted.2016 <- d.l.2016 %>%
rename(c(genome = "genome")) %>%
select(genome, counts) %>%
arrange(desc(counts))
d.l.2016
grouping.info.2013 <- maximize.likelihood(sorted.2013, 3)
sorted.2016 <- d.l.2016
grouping.info.2013 <- maximize.likelihood(sorted.2013, 3)
sorted.2013 <- d.l.2013
grouping.info.2013 <- maximize.likelihood(sorted.2013, 3)
sorted.2016 <- d.l.2016 %>%
select(genome, counts) %>%
arrange(desc(counts))
# First sort genotypes by abundance.
sorted.2013 <- d.l.2013 %>%
select(genome, counts) %>%
arrange(desc(counts))
sorted.2016 <- d.l.2016 %>%
select(genome, counts) %>%
arrange(desc(counts))
grouping.info.2013 <- maximize.likelihood(sorted.2013, 3)
print_groups(grouping.info.2013)
grouping.info.2013 <- maximize.likelihood(sorted.2013, 3)
maximize.likelihood <- function(data_set, K){
partitions <- combinations(nrow(data_set) - 1, K - 1)
best.likelihood = -1000000
for (i in 1:nrow(partitions))
{
breaks <- c(0,partitions[i,],nrow(data_set))
groups <- lapply(1:K, FUN=function(x){
data_set[(breaks[x]+1):breaks[x+1], 2]
})
group_members <- c(apply(array(1:K), 1, FUN=function(x){
length(data_set[(breaks[x]+1):breaks[x+1], 1])
}))
lambdas = sapply(groups, sum)
current.likelihood <- sum(sapply(1:K, FUN = function(x){
sum(log.likelihood(lambdas[x], groups[[x]]))
}))
if (current.likelihood > best.likelihood) {
best.likelihood = current.likelihood
best.partition = breaks[-c(1,length(breaks))]
best.lambdas = lambdas
best.group.members = group_members
}
}
return(list(Max_Likelihood = best.likelihood, Partitions = best.partition, Lambdas = best.lambdas, Group_Members = best.group.members))
}
grouping.info.2013 <- maximize.likelihood(sorted.2013, 3)
print(paste("Best grouping for 2013 had likelihood", grouping.info.2013[1]))
print_groups(grouping.info.2013)
print_groups(group_info = grouping.info.2013)
print_groups(sorted,2013,grouping.info.2013)
print_groups(sorted.2013,grouping.info.2013)
grouping.info.2013 <- maximize.likelihood(sorted.2013, 5)
print(paste("Best grouping for 2013 had likelihood", grouping.info.2013[1]))
print_groups(sorted.2013,grouping.info.2013)
grouping.info.2013 <- maximize.likelihood(sorted.2013, 3)
print(paste("Best grouping for 2013 had likelihood", grouping.info.2013[1]))
print_groups(sorted.2013,grouping.info.2013)
grouping.info.2013 <- maximize.likelihood(sorted.2013, 6)
print(paste("Best grouping for 2013 had likelihood", grouping.info.2013[1]))
print_groups(sorted.2013,grouping.info.2013)
print_groups <- function(data_set, group_info){
print("Groups: ")
breaks = c(0, group_info$Partitions, nrow(data_set))
groups <- apply(array(1:length(group_info$Lambdas)),1,FUN=function(x){
print(data_set[(breaks[x]+1):breaks[x+1], 1], max.levels = 0)
})
}
print_groups(sorted.2013,grouping.info.2013)
grouping.info.2013 <- maximize.likelihood(sorted.2013, 5)
print(paste("Best grouping for 2013 had likelihood", grouping.info.2013[1]))
print_groups(sorted.2013,grouping.info.2013)
grouping.info.2013 <- maximize.likelihood(sorted.2013, 3)
print(paste("Best grouping for 2013 had likelihood", grouping.info.2013[1]))
print_groups(sorted.2013,grouping.info.2013)
grouping.info.2016 <- maximize.likelihood(sorted.2016, 3)
print(paste("Best grouping for 2013 had likelihood", grouping.info.2016[1]))
print_groups(sorted.2016,grouping.info.2016)
sorted.2013.trimmed <- sorted.2013 %>% filter(counts != 0)
sorted.2016.trimmed <- sorted.2016 %>% filter(counts != 0)
grouping.info.2013.trimmed <- maximize.likelihood(sorted.2013.trimmed, 3)
print(paste("Best grouping for 2013 had likelihood", grouping.info.2013.trimmed[1]))
print_groups(sorted.2013.trimmed,grouping.info.2013)
grouping.info.2016.trimmed <- maximize.likelihood(sorted.2016.trimmed, 3)
print(paste("Best grouping for 2016 had likelihood", grouping.info.2016.trimmed[1]))
print_groups(sorted.2016.trimmed,grouping.info.2016)
maximize.likelihood.2 <- function(data_set, K){
# Finds the likeliest grouping of genome data into K groups.
# Assumes data_set is sorted by counts.
# All possible group breaks: There are |data_set| - 1 places to
# break the data into K groups by placing K - 1 markers.
partitions <- combinations(nrow(data_set) - 1, K - 1)
best.partition = 1:(K - 1)
best.likelihood = -1000000
for (i in 1:nrow(partitions))
{
breaks <- partitions[i, ]
print(breaks)
# groups <- splitAt(data_set[, 2], breaks)
# GET LAMBDAS
# GET LIKELIHOOD
# current.likelihood <- sum(log.likelihood(lambdas[1], group_1),
#                           log.likelihood(lambdas[2], group_2),
#                           log.likelihood(lambdas[3], group_3))
if (current.likelihood > best.likelihood) {
best.likelihood = current.likelihood
best.partition = breaks
}
}
return(c(best.likelihood, best.partition, lambdas))
}
# Find likelihood when K == 1.
B = 1000
K = 1
while (K < 19){
K = K + 1
K.partition.info <- maximize.likelihood.2(sorted.2013, K)
lambdas <- K.partition.info[4:6]
for (i in 1:B)
{
samples.x <- rpois(K, lambdas)
print(samples.x)
}
}
library(plyr)
library(gtools)
install.packages('gtools')
library(gtools)
library(tidyverse)
library(reshape)
install.packages('resshape')
library(reshape)
library(data.table)
install.packages('reshape')
library(reshape)
library(data.table)
setwd("C:/users/Schuyler/Dropbox/Classes/BCB_II/BCB_II_HW_3")
setwd("~/Dropbox/Classes/BCB_II/BCB_II_HW_3")
source("source.R")
### Reading data in
d <- read.csv("count_genome.csv", header=TRUE)
d.l <- reshape(d, varying = paste("X", 2009:2016, sep=""), v.names = "counts", timevar = "yr", time = 2009:2016, direction = "long")
colnames(d.l) <- c("genome", "yr", "counts", "id")
d.ll <- untable(d.l, d.l$counts)[, -c(3,4)]
###1b
##### 2013:
d.l.2013 <- filter(d.l, yr==2013)  #choose only 2013
d.l.2013 <- arrange(d.l.2013, genome) %>% #make sure genomes are in order
mutate(i = c(1:nrow(d.l.2013))) %>% #label data with the numbers "i"
mutate(p.hat.i=counts/(sum(d.l.2013$counts)), #make a column of the MLE p.hat.i = xi/n
var.p.hat.i=(p.hat.i)*(1-p.hat.i)/(sum(d.l.2013$counts)),
CI.90.upper = qnorm(0.95, mean=(p.hat.i), sd=(sqrt(var.p.hat.i))), #Make columns with 90% confidence interval bounds
CI.90.lower = qnorm(0.05, mean=(p.hat.i), sd=(sqrt(var.p.hat.i))))
ggplot(d.l.2013, aes(i,p.hat.i)) +
geom_pointrange(aes(ymin=CI.90.lower, ymax=CI.90.upper)) +
ggtitle("2013")
d.l.2016 <- filter(d.l, yr==2016)  #choose only 2016
d.l.2016 <- arrange(d.l.2016, genome) %>% #make sure genomes are in order
mutate(i = c(1:nrow(d.l.2016))) %>%
mutate(p.hat.i=counts/(sum(d.l.2016$counts)), #make a column of the MLE p.hat.i = xi/n
var.p.hat.i=(p.hat.i)*(1-p.hat.i)/(sum(d.l.2016$counts)),
CI.90.upper = qnorm(0.95, mean=(p.hat.i), sd=(sqrt(var.p.hat.i))), #Make columns with 90% confidence interval bounds
CI.90.lower = qnorm(0.05, mean=(p.hat.i), sd=(sqrt(var.p.hat.i))))
### plot MLE and confidence interval:
ggplot(d.l.2016, aes(i,p.hat.i)) +
geom_pointrange(aes(ymin=CI.90.lower, ymax=CI.90.upper)) +
ggtitle("2016")
### Wald test statistic (T) for each year = sqrt((p_hat_i - p)^2/(var(p_hat_i)))
### Here, comparing genomes A and B (1 and 2, respectively)
(T.2013 <- sqrt(((d.l.2013$p.hat.i[1] - d.l.2013$p.hat.i[2])^2) / (d.l.2013$var.p.hat.i[1])))
(T.2016 <- sqrt(((d.l.2016$p.hat.i[1] - d.l.2016$p.hat.i[2])^2) / (d.l.2016$var.p.hat.i[1])))
# T ~ chi-square with 1 df, so find P(T<=t):
# (P.2013 <- pnorm(T.2013, 0, 1))
# (P.2016 <- pnorm(T.2016, 0, 1))
(P.2013 <- pchisq(T.2013, 1))
(P.2016 <- pchisq(T.2016, 1))
# Were A and B significantly different in either year? With two-tailed test, a=.05
(significant.2013 <- (P.2013 >= .975 | P.2013 < .025))
(significant.2016 <- (P.2016 >= .975 | P.2016 < .025))
